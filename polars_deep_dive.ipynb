{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import resource\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split a str column of a polars into different columns based on separator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this section is to be able to create different columns from a single column that contains multiples substrings. For example \"cat_dog_parrot\"\n",
    "\n",
    "The section is creating expanding the stack overflow answer: [https://stackoverflow.com/questions/73699500/python-polars-split-string-column-into-many-columns-by-delimiter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fake dataframe\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"my_str\": [\"cat\", \"cat/dog\", None, \"\", \"cat/dog/aardvark/mouse/frog\"],\n",
    "        \"another_column\": [1,2,3,4,5]\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "string_sepator = \"/\"\n",
    "column_to_split = \"my_str\"\n",
    "# if we have additional columns other then the str column\n",
    "other_cols_to_keep = [\"another_column\"]\n",
    "# prefix of the new str column, ex. if the value is \"name\"\n",
    "# the names of the new columns will be \"name01\", \"name02\", ...\n",
    "new_str_column_prefix = column_to_split\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_str_df = (\n",
    "    df\n",
    "    .with_row_count('id')\n",
    "    .with_columns(pl.col(column_to_split).str.split(string_sepator).alias(\"split_str\"))\n",
    "    .explode(\"split_str\")\n",
    "    .with_columns(\n",
    "        (new_str_column_prefix + \"_\" + pl.arange(0, pl.count()).cast(pl.Utf8).str.zfill(2))\n",
    "        .over(\"id\")\n",
    "        .alias(\"col_nm\")\n",
    "    )\n",
    "    .pivot(\n",
    "        index=['id', 'my_str'] + other_cols_to_keep,\n",
    "        values='split_str',\n",
    "        columns='col_nm',\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(f'^{new_str_column_prefix}_.*$').fill_null(\"\")\n",
    "    )\n",
    ")\n",
    "\n",
    "splitted_str_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a function to all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    pl.all().cast(str) + \"_test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## withcolumns with list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_str_df.with_columns(\n",
    "    [(pl.col(col).cast(str)+\"_test\").alias(f\"{col}_test\") for col in splitted_str_df.columns]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polars selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"w\": [\"xx\", \"yy\", \"xx\", \"yy\", \"xx\"],\n",
    "        \"x\": [1, 2, 1, 4, -2],\n",
    "        \"y\": [3.0, 4.5, 1.0, 2.5, -2.0],\n",
    "        \"z\": [\"a\", \"b\", \"a\", \"b\", \"b\"],\n",
    "    },\n",
    ")\n",
    "# group by str columns, sum all numeric\n",
    "df.group_by(by=cs.string()).agg(cs.numeric().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polars fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame(\n",
    "\n",
    "    {\n",
    "\n",
    "        \"a\": [2, 1, 3],\n",
    "\n",
    "        \"b\": [1, 2, 3],\n",
    "\n",
    "        \"c\": [1.0, 2.0, 3.0],\n",
    "\n",
    "    }\n",
    "\n",
    ")\n",
    "\n",
    "df.fold(lambda s1, s2: s1 + s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform a column passing transformation dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code_dict = {\n",
    "    \"CA\": \"Canada\",\n",
    "    \"DE\": \"Germany\",\n",
    "    \"FR\": \"France\",\n",
    "    None: \"Not specified\",\n",
    "}\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"country_code\": [\"FR\", None, \"ES\", \"DE\"],\n",
    "    }\n",
    ").with_row_count()\n",
    "\n",
    "df = df.with_columns(\n",
    "    pl.col(\"country_code\").map_dict(\n",
    "        country_code_dict, \n",
    "        # default=\"unknown\"\n",
    "    ).alias(\"remapped\")\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test a condition on multiple columns, keep only rows that satisfy the condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict = {\"country_code\": [\"FR\", \"DE\"], \"remapped\": [\"France\", \"test\"]}\n",
    "my_test = df.select(\n",
    "    [pl.col(col).is_in(value) for col, value in col_dict.items()]\n",
    ").select(\n",
    "    pl.all_horizontal(\"*\").alias(\"keep_row\")\n",
    ")\n",
    "pl.concat(\n",
    "    [df, my_test],\n",
    "    how=\"horizontal\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle non relational dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a non relational dataframe that is composed by several relational dataframe\n",
    "concatenated vertically. The unique names of the columns are contained in the columns_id_column column and the value of the columns is contained in the value column.\n",
    "\n",
    "1) Create a column initialized with the null value for every unique value in columns_id_column \n",
    "2) For every row fill the value of the column related to the measure of that row\n",
    "3) remove the columns that does not satisfy a minimum threshold\n",
    "4) Do a mergeasof join between the features dataset and the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Create the data\n",
    "data = {\n",
    "    \"_time\": [datetime(2023, 1, 1) + timedelta(days = i) for i in range(3000)],\n",
    "    \"_field\": [\"A\", \"B\", \"C\"]*1000,\n",
    "    \"_value\": [randint(1, 100) for _ in range(3000)]\n",
    "}\n",
    "\n",
    "# Create the Polars DataFrame\n",
    "df = pl.DataFrame(\n",
    "    data, \n",
    "    schema={\n",
    "        \"_time\": datetime,\n",
    "        \"_field\": str,\n",
    "        \"_value\": int\n",
    "    }\n",
    ")\n",
    "\n",
    "# Assuming you have the previous DataFrames 'df' and 'df_box_lotti'\n",
    "common_time = df['_time'][0]  # Common time value shared with 'df'\n",
    "\n",
    "# Create additional rows with different _time values\n",
    "end_time_values = (\n",
    "    [\n",
    "            common_time - timedelta(days = i) \n",
    "            for i in range(1,101)\n",
    "    ] \n",
    "    + [\n",
    "        common_time + timedelta(days = i) \n",
    "        for i in range(1,101)\n",
    "    ]\n",
    ")\n",
    "\n",
    "additional_data = {\n",
    "    \"end_time\": end_time_values        \n",
    "    , \"label\": [randint(0, 1) for _ in range(1,201)]\n",
    "}\n",
    "\n",
    "# Append the additional rows to the existing 'df_box_lotti' DataFrame\n",
    "df_box_lotti = pl.DataFrame(additional_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_time = time.time()\n",
    "\n",
    "time_column = \"_time\"\n",
    "columns_id_column = \"_field\"\n",
    "value_column = \"_value\"\n",
    "# time column name for the right dataframe in merge as of\n",
    "right_time_column = \"end_time\"\n",
    "var_fisiche = list(df[columns_id_column].unique())\n",
    "# minimum number of appearances that a value of columns_id_column should have\n",
    "# to be kept in the final dataframe\n",
    "min_num_var_fisiche = 20\n",
    "\n",
    "# we want to create columns for all the var_fisiche\n",
    "# but at this step in every row all the columns will be null \n",
    "# except the column with the name equal to the _field value in that row.\n",
    "# Later on we will groupby time stamp and put in the same row\n",
    "# all the phisical measurements related to that time stamp\n",
    "df_relazionale = df.with_columns(\n",
    "    [\n",
    "        (\n",
    "            pl.when(pl.col(columns_id_column) == var).then(pl.col(value_column)).otherwise(pl.lit(None))\n",
    "        ).alias(var) for var in var_fisiche\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# print time needed and memory usage\n",
    "usage = resource.getrusage(resource.RUSAGE_SELF)\n",
    "time_record = f\"Time create row data for var fisiche: {round(time.time()-old_time,2)}, memory usage: {round(usage.ru_maxrss / (1024 * 1024),2)}GB\"\n",
    "print(time_record)\n",
    "old_time = time.time()\n",
    "\n",
    "numerosita_var_fisiche = (\n",
    "    df_relazionale.select(\n",
    "        var_fisiche\n",
    "    ).select(\n",
    "        pl.all().is_not_null().sum()\n",
    "    ).to_dicts()[0]\n",
    ")\n",
    "# filter out columns with low numerosity\n",
    "var_fisiche_to_select = [\n",
    "    key \n",
    "    for key, value in numerosita_var_fisiche.items() \n",
    "    if value > min_num_var_fisiche\n",
    "]\n",
    "\n",
    "df_relazionale_ridotto = df_relazionale.select(\n",
    "    [time_column] + var_fisiche_to_select\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the min time instant in df_relazionale_ridotto\n",
    "# to filter out end_times in df_box_lotti that \n",
    "# happens before this minimum time\n",
    "min_var_fisiche_time = df_relazionale_ridotto[time_column].min()\n",
    "\n",
    "# sort variables before performing merge_as_of\n",
    "# this should be done in polars with set_sorted before join_asof\n",
    "df_box_lotti = df_box_lotti.sort(\n",
    "    by=right_time_column\n",
    ").set_sorted(right_time_column)\n",
    "df_relazionale_ridotto = df_relazionale_ridotto.sort(\n",
    "    by=time_column\n",
    ").set_sorted(time_column)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute final dataset with merge_as_of\n",
    "# Merge all the rows in the left dataframe with the nearest row in the left\n",
    "# dataframe that has a value of time_column <= right_time_column\n",
    "complete_df = (\n",
    "    df_relazionale_ridotto.join_asof(\n",
    "        df_box_lotti.filter(\n",
    "            (pl.col(right_time_column) > min_var_fisiche_time)\n",
    "        ), \n",
    "        strategy=\"forward\", left_on = time_column, right_on = right_time_column\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby with list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = complete_df.groupby(\n",
    "    ['LOT_NUMBER', 'BOX_NUMBER']\n",
    ").agg( \n",
    "    [\n",
    "        pl.col('CONFORMITY').first(),\n",
    "        pl.col('NC_REASON').first(),\n",
    "        pl.col('NC_DESCRIPTION').first(),        \n",
    "    ] +\n",
    "    [ \n",
    "        pl.when(\n",
    "                pl.col(col).is_not_null().sum()>0\n",
    "            ).then(pl.col(col).mean().cast(float)\n",
    "            ).otherwise(None).alias(f\"mean_{col}\")\n",
    "        for col in var_fisiche_to_select if col != \"BOX_number\"      \n",
    "    ]  \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
